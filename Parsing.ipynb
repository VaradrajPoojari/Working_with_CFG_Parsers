{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with CFG Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment requires that you have set up the Stanford parser. First, make sure you have the more recent version of [Java](https://www.java.com/en/download/), then get the [Stanford CoreNLP](https://stanfordnlp.github.io/CoreNLP/) package. Make sure that you get the 4.3.2 version (or at least >=4.2.0). \n",
    "\n",
    "To load Stanford CoreNLP in Python, change the `coreNLP_dir` variable in the code below to where you unzipped Stanford coreNLP. You can follow this [tutorial](https://bbengfort.github.io/snippets/2018/06/22/corenlp-nltk-parses.html). Once the coreNLP server is running, you will be able to access it through NLTK.\n",
    "\n",
    "It may take a few seconds or up to a minute to start the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPServer\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "coreNLP_dir = \"/Users/varadrajrameshpoojary/Downloads/stanford-corenlp-4.3.2\" # Change this to your coreNLP directory\n",
    "\n",
    "server = CoreNLPServer(\n",
    "   os.path.join(coreNLP_dir, \"stanford-corenlp-4.3.2.jar\"),\n",
    "   os.path.join(coreNLP_dir, \"stanford-corenlp-4.3.2-models.jar\")    \n",
    ")\n",
    "server.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parsed a sentence to make sure that everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (NP (PRP I))\n",
      "    (VP\n",
      "      (VBD put)\n",
      "      (NP (DT the) (NN book))\n",
      "      (PP (IN in) (NP (DT the) (NN box)))\n",
      "      (PP (IN on) (NP (DT the) (NN table))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "\n",
    "parser = CoreNLPParser()\n",
    "parse = next(parser.raw_parse(\"I put the book in the box on the table.\"))\n",
    "print(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (NP (PRP They))\n",
      "    (VP\n",
      "      (VBD gave)\n",
      "      (NP (PRP me))\n",
      "      (NP (ADJP (JJ yellow) (CC and) (JJ blue)) (NNS pants)))))\n"
     ]
    }
   ],
   "source": [
    "parse = next(parser.raw_parse(\"They gave me yellow and blue pants\"))\n",
    "print(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below if you want to shut down the coreNLP server after you've finished with it. It's a good idea to shut down the parser after finishing work with it because it may remain running in the background and you may not be able to start another parser instance without restarting your computer or manually killing the parser process. \n",
    "\n",
    "If you forget to stop the server, next time when you try to launch it, you'll get an error. In this case, you may first need to kill the old server manually. To do this, you can run `ps -ax | grep stanford` on the commandline (at least on OSX and Linux) which should give you the process ID of the server, e.g. 11111. You can then use `kill -9 11111` to kill the parser, after which you should be able to start the server again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    server.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things you'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/varadrajrameshpoojary/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk.grammar import CFG,Nonterminal,Production,FeatureGrammar\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then parse the first 20 sentences of the NLTK `movie_reviews` corpus, and report the average depth (height) of the parse trees.\n",
    "\n",
    "To retain the tokenization in the `move_reviews` corpus. You can use `parser.parse()` to parse the tokenized input sentences. Note that `parser.parse()` returns an iterator over possible parses. There may be several if the sentence is ambiguous. You can compute statistics on the first sentence which is returned by `parser.parse()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "# your code here\n",
    "test_set= movie_reviews.sents()[:20]\n",
    "height_list = []\n",
    "for sentence in test_set:\n",
    "    try:\n",
    "        parse = next(parser.parse(sentence))\n",
    "        height_list.append(parse.height())\n",
    "        \n",
    "    except Exception:\n",
    "        pass \n",
    "print(sum(height_list)/len(height_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a gold standard\n",
    "\n",
    "One typical way to build treebanks is, rather than having humans build a tree from scratch, instead use an automatic parser to give an initial parse, and then have humans do a second pass to fix any errors. \n",
    "\n",
    "We will use the following three sentences from the NLTK `movie_reviews` corpus to build a mini-treebank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [['oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.'],\n",
    "          ['little', 'do', 'they', 'know', 'the', 'power', 'within', '.'],\n",
    "          ['so', ',', 'if', 'robots', 'and', 'body', 'parts', 'really', 'turn', 'you', 'on', ',', 'here', \"'\", 's', 'your', 'movie', '.']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each of the three sections below you will see a parse tree produced by CorNLPParser. Each of the trees contains at least one parse error.  \n",
    "\n",
    "Create an NLTK Tree corresponding to the correct parse, which should be appended to the `gold_standard_parses` list below. You can do this manually by printing the tree, creating a triple-quoted string, modifying it, and converting it back into a `Tree` using the function `Tree.fromstring` following the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NNS Dogs)) (VP (VBN bark)) (. .))\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "# The second phrase should be an VP, not an NP\n",
    "err_tree_str = '''(S\n",
    "(NP (NNS Dogs)) \n",
    "(NP (VBN bark))\n",
    "(. .))\n",
    "'''\n",
    "\n",
    "corr_tree_str = '''(S\n",
    "(NP (NNS Dogs)) \n",
    "(VP (VBN bark))\n",
    "(. .))\n",
    "'''\n",
    "\n",
    "corr_tree = Tree.fromstring(corr_tree_str)\n",
    "print(corr_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your corrected nltk.Tree objects in this list\n",
    "gold_standard_parses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_tree_str:\n",
      "                                       S                                                   \n",
      "  _____________________________________|_________________________________________________   \n",
      " |    |   |       |           |   |                     VP                               | \n",
      " |    |   |       |           |   |     ________________|_____                           |  \n",
      " |    |   |       |           |   |    |   |                  NP                         | \n",
      " |    |   |       |           |   |    |   |        __________|______________            |  \n",
      " |    |   |       PP          |   |    |   |       |          |              NP          | \n",
      " |    |   |    ___|___        |   |    |   |       |          |         _____|______     |  \n",
      "INTJ  |   |   |       NP      |   NP   |   |       NP         |       NML           |    | \n",
      " |    |   |   |    ___|___    |   |    |   |    ___|____      |    ____|_____       |    |  \n",
      " UH   ,   CC  IN  DT      NN  ,   DT  VBZ  RB  DT       NN    CC  NN         NN     NN   . \n",
      " |    |   |   |   |       |   |   |    |   |   |        |     |   |          |      |    |  \n",
      " oh   ,  and  by the     way  ,  this  is not  a      horror  or teen     slasher flick  . \n",
      "\n",
      "corr_tree_str:\n",
      "                                       S                                               \n",
      "  _____________________________________|__________________                              \n",
      " |    |   |       |           |   |                       VP                           \n",
      " |    |   |       |           |   |     __________________|__________________________   \n",
      " |    |   |       |           |   |    |   |                  NP                     | \n",
      " |    |   |       |           |   |    |   |               ___|_________________     |  \n",
      " |    |   |       PP          |   |    |   |              NP                    |    | \n",
      " |    |   |    ___|___        |   |    |   |    __________|________             |    |  \n",
      "INTJ  |   |   |       NP      |   NP   |   |   |    |     |       NML           |    | \n",
      " |    |   |   |    ___|___    |   |    |   |   |    |     |    ____|_____       |    |  \n",
      " UH   ,   CC  IN  DT      NN  ,   DT  VBZ  RB  DT   NN    CC  NN         NN     NN   . \n",
      " |    |   |   |   |       |   |   |    |   |   |    |     |   |          |      |    |  \n",
      " oh   ,  and  by the     way  ,  this  is not  a  horror  or teen     slasher flick  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The word \"flick\" should be modified by the entire noun phrase \n",
    "# \"a horror or teen slasher\" instead of just \"teen slasher\". A noun \n",
    "# phrase which modifies a noun is labeled as NML.\n",
    "err_tree_str = '''(ROOT\n",
    "  (S\n",
    "    (INTJ (UH oh))\n",
    "    (, ,)\n",
    "    (CC and)\n",
    "    (PP (IN by) (NP (DT the) (NN way)))\n",
    "    (, ,)\n",
    "    (NP (DT this))\n",
    "    (VP\n",
    "      (VBZ is)\n",
    "      (RB not)\n",
    "      (NP\n",
    "        (NP (DT a) (NN horror))\n",
    "        (CC or)\n",
    "        (NP (NML (NN teen) (NN slasher)) (NN flick))))\n",
    "    (. .)))'''\n",
    "\n",
    "# your code here\n",
    "corr_tree_str = '''(ROOT\n",
    "  (S\n",
    "    (INTJ (UH oh))\n",
    "    (, ,)\n",
    "    (CC and)\n",
    "    (PP (IN by) (NP (DT the) (NN way)))\n",
    "    (, ,)\n",
    "    (NP (DT this))\n",
    "    (VP\n",
    "      (VBZ is)\n",
    "      (RB not)\n",
    "      (NP\n",
    "        (NP (DT a) (NN horror)\n",
    "        (CC or)\n",
    "        (NML (NN teen) (NN slasher))) (NN flick))\n",
    "    (. .))))'''\n",
    "print(\"err_tree_str:\")\n",
    "list(Tree.fromstring(err_tree_str))[0].pretty_print()\n",
    "print(\"corr_tree_str:\")\n",
    "list(Tree.fromstring(corr_tree_str))[0].pretty_print()\n",
    "\n",
    "gold_standard_parses.append(Tree.fromstring(corr_tree_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_tree_str:\n",
      "                 S                           \n",
      "   ______________|_________________________   \n",
      "  |         VP                             | \n",
      "  |      ___|____                          |  \n",
      "  |     |       SBAR                       | \n",
      "  |     |        |                         |  \n",
      "  |     |        S                         | \n",
      "  |     |    ____|____                     |  \n",
      "  |     |   |         VP                   | \n",
      "  |     |   |     ____|______________      |  \n",
      "  NP    |   NP   |        NP         PP    | \n",
      "  |     |   |    |     ___|____      |     |  \n",
      "  RB   VBP PRP  VBP   DT       NN    IN    . \n",
      "  |     |   |    |    |        |     |     |  \n",
      "little  do they know the     power within  . \n",
      "\n",
      "corr_tree_str:\n",
      "                 S                            \n",
      "   ______________|__________________________   \n",
      "  |              VP                         | \n",
      "  |      ________|____                      |  \n",
      "  |     |            SBAR                   | \n",
      "  |     |             |                     |  \n",
      "  |     |             S                     | \n",
      "  |     |    _________|____                 |  \n",
      "  |     |   |              VP               | \n",
      "  |     |   |     _________|____            |  \n",
      "  |     |   |    |              NP          | \n",
      "  |     |   |    |     _________|_____      |  \n",
      "  NP    |   NP   |    |         |     PP    | \n",
      "  |     |   |    |    |         |     |     |  \n",
      "  RB   VBP PRP  VBP   DT        NN    IN    . \n",
      "  |     |   |    |    |         |     |     |  \n",
      "little  do they know the      power within  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The PP \"within\" should attach to the NP \"the power\", not to the VP \"know the power\". \n",
    "err_tree_str = '''(ROOT\n",
    "  (S\n",
    "    (NP (RB little))\n",
    "    (VP\n",
    "      (VBP do)\n",
    "      (SBAR\n",
    "        (S\n",
    "          (NP (PRP they))\n",
    "          (VP (VBP know) (NP (DT the) (NN power)) (PP (IN within))))))\n",
    "    (. .)))'''\n",
    "\n",
    "# your code here\n",
    "\n",
    "corr_tree_str = '''(ROOT\n",
    "  (S\n",
    "    (NP (RB little))\n",
    "    (VP\n",
    "      (VBP do)\n",
    "      (SBAR\n",
    "        (S\n",
    "          (NP (PRP they))\n",
    "          (VP (VBP know) (NP (DT the) (NN power) (PP (IN within)))))))\n",
    "    (. .)))'''\n",
    "print(\"err_tree_str:\")\n",
    "list(Tree.fromstring(err_tree_str))[0].pretty_print()\n",
    "print(\"corr_tree_str:\")\n",
    "list(Tree.fromstring(corr_tree_str))[0].pretty_print()\n",
    "\n",
    "gold_standard_parses.append(Tree.fromstring(corr_tree_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_tree_str:\n",
      "                                              SINV                                            \n",
      "  _____________________________________________|____________________________________________   \n",
      " |    |              |                   |                  VP                    |         | \n",
      " |    |              |                   |      ____________|____________         |         |  \n",
      " |    |              PP                  |     |            NP           |        |         | \n",
      " |    |    __________|___                |     |     _______|________    |        |         |  \n",
      " |    |   |              NP              |     |    |       PP       |   S        |         | \n",
      " |    |   |           ___|_________      |     |    |    ___|___     |   |        |         |  \n",
      "ADVP  |   |         NML            |    ADVP   |    NP  |   |   NP   |   NP       NP        | \n",
      " |    |   |     _____|_______      |     |     |    |   |   |   |    |   |    ____|____     |  \n",
      " RB   ,   IN  NNS    CC      NN   NNS    RB   VBP  PRP  IN  ,   RB   '' POS PRP$       NN   . \n",
      " |    |   |    |     |       |     |     |     |    |   |   |   |    |   |   |         |    |  \n",
      " so   ,   if robots and     body parts really turn you  on  ,  here  '   s  your     movie  . \n",
      "\n",
      "corr_tree_str:\n",
      "                                              SINV                                                   \n",
      "  _____________________________________________|____                                                  \n",
      " |    |                                             PP                                               \n",
      " |    |    _________________________________________|_______________                                  \n",
      " |    |   |          |                   |                          VP                               \n",
      " |    |   |          |                   |      ____________________|_________                        \n",
      " |    |   |          NP                  |     |        |       |           CLAUSE                   \n",
      " |    |   |          |                   |     |        |       |    _________|____________________   \n",
      " |    |   |         NML                  |     |        NP      |   |    |    S          |         | \n",
      " |    |   |     _____|________           |     |     ___|___    |   |    |    |          |         |  \n",
      "ADVP  |   |    |     |        NP        ADVP   |    NP      PP  |   NP   |    VB         NP        | \n",
      " |    |   |    |     |    ____|____      |     |    |       |   |   |    |    |      ____|____     |  \n",
      " RB   ,   IN  NNS    CC  NN       NNS    RB   VBP  PRP      IN  ,   RB   ''  POS   PRP$       NN   . \n",
      " |    |   |    |     |   |         |     |     |    |       |   |   |    |    |     |         |    |  \n",
      " so   ,   if robots and body     parts really turn you      on  ,  here  '    s    your     movie  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are several errors.\"body\" and \"parts\" should form an NP. \n",
    "# Moreover, \"here's your movie\" should form a clause and \"s\" is in \n",
    "# fact a verb.  \n",
    "err_tree_str = '''(ROOT\n",
    "  (SINV\n",
    "    (ADVP (RB so))\n",
    "    (, ,)\n",
    "    (PP\n",
    "      (IN if)\n",
    "      (NP (NML (NNS robots) (CC and) (NN body)) (NNS parts)))\n",
    "    (ADVP (RB really))\n",
    "    (VP\n",
    "      (VBP turn)\n",
    "      (NP (NP (PRP you)) (PP (IN on) (, ,) (NP (RB here))) ('' '))\n",
    "      (S (NP (POS s))))\n",
    "    (NP (PRP$ your) (NN movie))\n",
    "    (. .)))'''\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "corr_tree_str = '''(ROOT\n",
    "  (SINV\n",
    "    (ADVP (RB so))\n",
    "    (, ,)\n",
    "    (PP\n",
    "      (IN if)\n",
    "      (NP (NML (NNS robots) (CC and) (NP(NN body) (NNS parts))))\n",
    "    (ADVP (RB really))\n",
    "    (VP\n",
    "      (VBP turn)\n",
    "      (NP (NP (PRP you)) (PP (IN on))) (, ,) (CLAUSE (NP (RB here)) ('' ')\n",
    "      (S (VB (POS s)))\n",
    "    (NP (PRP$ your) (NN movie))\n",
    "    (. .))))))'''\n",
    "print(\"err_tree_str:\")\n",
    "list(Tree.fromstring(err_tree_str))[0].pretty_print()\n",
    "print(\"corr_tree_str:\")\n",
    "list(Tree.fromstring(corr_tree_str))[0].pretty_print()\n",
    "\n",
    "\n",
    "gold_standard_parses.append(Tree.fromstring(corr_tree_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a gold standard, we can use it to evaluate parser output. \n",
    "\n",
    "\n",
    "We start by writing a function, get_constituents, which takes a parse tree and returns a set of tuples, where each tuple is (*label*, *start*, *end*) where *start* and *end* correspond to the indicies of a corresponding constituent (phrase) in the sentence and *label* is the label of that constituent. \n",
    "\n",
    "We do **not** include simple POS constituents `(POS word)` like `(VBD ate)`. We want to evaluate the parser only on actual phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constituents(tree,start_index=0):\n",
    "    constituents = set()\n",
    "    if tree.height() > 2:\n",
    "        constituents.add((tree.label(), start_index, start_index+len(tree.leaves())))\n",
    "        for node in tree:\n",
    "            constituents.update(get_constituents(node, start_index))\n",
    "            start_index += len(node.leaves())\n",
    "    return constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.fromstring('''(S (NP (DT the) (DT mouse)) (VP (VBD ate) (NP (NP (DT the) (DT mouse)) (POS 's) (NN cheese))) )''')\n",
    "assert get_constituents(tree) == {(\"S\",0,7), (\"NP\",0,2), (\"VP\",2,7),(\"NP\",3,7),(\"NP\",3,5)}\n",
    "tree = Tree.fromstring('''(S (NP (DET the) (NP (NN cat) (CC and) (NN dog))) (VP (VBD fought)))''')\n",
    "assert get_constituents(tree) == {(\"S\",0,5), (\"NP\",0,4), (\"NP\",1,4),(\"VP\",4,5)}\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function `parse_f1` which uses get_constituents to implement the constituent F-score measure. It should be given two lists, a lists of proposed parses and a corresponding list of gold standard parses, and return an F-score reflecting how close the proposed parses match. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_f1(proposed_parses,gold_parses):\n",
    "    f1score = 0\n",
    "    # your code here\n",
    "    match_count = 0\n",
    "    total_gold_count =0\n",
    "    total_proposed_count =0\n",
    "    for gold,proposed in zip(gold_parses,proposed_parses):\n",
    "        gold_parse_set = get_constituents(gold)\n",
    "        proposed_parse_set = get_constituents(proposed)\n",
    "        match_count += len(gold_parse_set & proposed_parse_set)\n",
    "        total_gold_count += len(gold_parse_set)\n",
    "        total_proposed_count += len(proposed_parse_set )\n",
    "    precision = match_count/total_proposed_count\n",
    "    recall = match_count/total_gold_count\n",
    "    f1score = 2*((precision*recall)/(precision+recall))\n",
    "    print(f1score)\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823529411765\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "gold_parses = [Tree.fromstring('''(S (NP (DT the) (DT mouse)) (VP (VBD ate) (NP (NP (DT the) (DT mouse)) (POS 's) (NN cheese))) )'''), Tree.fromstring('''(S (NP (NNS mice)) (VP (VBD love) (NP (NNS ducks))))''')]\n",
    "proposed_parses = [Tree.fromstring('''(S (NP (DT the) (DT mouse)) (VP (VBD ate) (NP (NP (DT the) (DT mouse)) (POS 's) (NN cheese))) )'''), Tree.fromstring('''(S (NP (NNS mice) (NN love)) (VP (VBZ ducks)))''')]\n",
    "assert 0.71> parse_f1(proposed_parses,gold_parses) > 0.7\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we parse our three example sentences from above using CoreNLPParser (you can find the sentences in the list `corpus`), extract the constituents and evaluate the result against `gold_standard_parses`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7123287671232876\n",
      "Parser f1-score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "parsed_corpus = [next(parser.parse(s)) for s in corpus]\n",
    "print(\"Parser f1-score: %.2f\" % parse_f1(parsed_corpus, gold_standard_parses))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a grammar\n",
    "\n",
    "Parse trees implicitly contain the production rules for a CFG defined by the productions which are present in the parse tree. You can access these productions using the member function `nltk.Tree.productions()`. \n",
    "\n",
    "We produce a grammar corresponding to the CFG productions in our three sentences, and print it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [['oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.'],\n",
    "          ['little', 'do', 'they', 'know', 'the', 'power', 'within', '.'],\n",
    "          ['so', ',', 'if', 'robots', 'and', 'body', 'parts', 'really', 'turn', 'you', 'on', ',', 'here', \"'\", 's', 'your', 'movie', '.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". -> '.'\n",
      "DT -> 'this'\n",
      "NN -> 'body'\n",
      "DT -> 'a'\n",
      "NP -> PRP$ NN\n",
      "'' -> \"'\"\n",
      "UH -> 'oh'\n",
      "PRP -> 'you'\n",
      "NN -> 'slasher'\n",
      "S -> NP VP\n",
      "IN -> 'within'\n",
      "SINV -> ADVP , PP\n",
      "RB -> 'so'\n",
      "NP -> RB\n",
      "NML -> NNS CC NP\n",
      "PP -> IN\n",
      "VP -> VBP NP , CLAUSE\n",
      "VP -> VBP SBAR\n",
      "DT -> 'the'\n",
      "IN -> 'by'\n",
      "NNS -> 'robots'\n",
      "NN -> 'horror'\n",
      "ROOT -> S\n",
      "VBZ -> 'is'\n",
      "NN -> 'movie'\n",
      "NN -> 'flick'\n",
      "VB -> POS\n",
      "S -> INTJ , CC PP , NP VP\n",
      "RB -> 'little'\n",
      "NNS -> 'parts'\n",
      "PP -> IN NP\n",
      "VBP -> 'do'\n",
      "NN -> 'power'\n",
      "NML -> NN NN\n",
      "NN -> 'way'\n",
      "NP -> DT\n",
      "PRP -> 'they'\n",
      "VP -> VBP NP\n",
      "ROOT -> SINV\n",
      "NP -> NML\n",
      "NP -> NN NNS\n",
      "VBP -> 'turn'\n",
      "SBAR -> S\n",
      "IN -> 'on'\n",
      "S -> NP VP .\n",
      "NN -> 'teen'\n",
      "POS -> 's'\n",
      "RB -> 'really'\n",
      "CC -> 'or'\n",
      "PP -> IN NP ADVP VP\n",
      "NP -> NP NN\n",
      "PRP$ -> 'your'\n",
      "ADVP -> RB\n",
      "IN -> 'if'\n",
      "NP -> PRP\n",
      "INTJ -> UH\n",
      ", -> ','\n",
      "NP -> DT NN CC NML\n",
      "NP -> DT NN PP\n",
      "NP -> DT NN\n",
      "RB -> 'here'\n",
      "NP -> NP PP\n",
      "CLAUSE -> NP '' S NP .\n",
      "S -> VB\n",
      "RB -> 'not'\n",
      "VP -> VBZ RB NP .\n",
      "VBP -> 'know'\n",
      "CC -> 'and'\n"
     ]
    }
   ],
   "source": [
    "rules = set()\n",
    "\n",
    "# your code here\n",
    "for tree in gold_standard_parses:\n",
    "    rule_list= tree.productions()\n",
    "    for i in rule_list:\n",
    "        rules.add(i)\n",
    "\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We show the rules are indeed sufficient to parse the sentences in the list `corpus`. Using an NLTK EarleyChartParser parser for this. Print out the number of parses for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parses for ['oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.']:\n",
      "Number of Parses : \n",
      " 2\n",
      "Parses for ['little', 'do', 'they', 'know', 'the', 'power', 'within', '.']:\n",
      "Number of Parses : \n",
      " 6\n",
      "Parses for ['so', ',', 'if', 'robots', 'and', 'body', 'parts', 'really', 'turn', 'you', 'on', ',', 'here', \"'\", 's', 'your', 'movie', '.']:\n",
      "Number of Parses : \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from nltk.parse import EarleyChartParser\n",
    "\n",
    "# your code here\n",
    "nltk_parser = EarleyChartParser(CFG(Nonterminal('ROOT'), rules), trace=0)\n",
    "    \n",
    "for sent in corpus:\n",
    "    print(\"Parses for %s:\" % sent)\n",
    "    parses = list(nltk_parser.parse(sent))\n",
    "    print(\"Number of Parses : \\n\", len(parses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
